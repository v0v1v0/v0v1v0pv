<div class="container">

<table style="width: 100%;"><tr>
<td>varband_cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Perform nfolds-cross validation</h2>

<h3>Description</h3>

<p>Select tuning parameter by cross validation according to the likelihood on testing data, with and without refitting.
</p>


<h3>Usage</h3>

<pre><code class="language-R">varband_cv(x, w = FALSE, lasso = FALSE, lamlist = NULL, nlam = 60,
  flmin = 0.01, folds = NULL, nfolds = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A n-by-p sample matrix, each row is an observation of the p-dim random vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>Logical. Should we use weighted version of the penalty or not? If <code>TRUE</code>, we use general weight. If <code>FALSE</code>, use unweighted penalty. Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lasso</code></td>
<td>
<p>Logical. Should we use l1 penalty instead of hierarchical group lasso penalty? Note that by using l1 penalty, we lose the banded structure in the resulting estimate. And when using l1 penalty, the becomes CSCS (Convex Sparse Cholesky Selection) introduced in Khare et al. (2016). Default value for <code>lasso</code> is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lamlist</code></td>
<td>
<p>A list of non-negative tuning parameters <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlam</code></td>
<td>
<p>If lamlist is not provided, create a lamlist with length <code>nulam</code>. Default is 60.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>flmin</code></td>
<td>
<p>If lamlist is not provided, create a lamlist with ratio of the smallest and largest lambda in the list equal to <code>flmin</code>. Default is 0.01.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>Folds used in cross-validation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>If folds are not provided, create folds of size <code>nfolds</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list object containing </p>

<dl>
<dt>errs_fit: </dt>
<dd>
<p>A <code>nlam</code>-by-<code>nfolds</code> matrix of negative Gaussian log-likelihood values on the CV test data sets. <code>errs[i,j]</code> is negative Gaussian log-likelihood values incurred in using <code>lamlist[i]</code> on fold <code>j</code></p>
</dd>
</dl>
<p>.
</p>
<dl>
<dt>errs_refit: </dt>
<dd>
<p>A <code>nlam</code>-by-<code>nfolds</code> matrix of negative Gaussian log-likelihood values of the refitting.</p>
</dd>
<dt>folds: </dt>
<dd>
<p>Folds used in cross validation.</p>
</dd>
<dt>lamlist: </dt>
<dd>
<p><code>lambda</code> grid used in cross validation.</p>
</dd>
<dt>ibest_fit: </dt>
<dd>
<p>index of <code>lamlist</code> minimizing CV negative Gaussian log-likelihood.</p>
</dd>
<dt>ibest_refit: </dt>
<dd>
<p>index of <code>lamlist</code> minimizing refitting CV negative Gaussian log-likelihood.</p>
</dd>
<dt>i1se_fit: </dt>
<dd>
<p>Selected value of <code>lambda</code> using the one-standard-error rule.</p>
</dd>
<dt>i1se_refit: </dt>
<dd>
<p>Selected value of <code>lambda</code> of the refitting process using the one-standard-error rule.</p>
</dd>
<dt>L_fit: </dt>
<dd>
<p>Estimate of L corresponding to <code>ibest_fit</code>.</p>
</dd>
<dt>L_refit: </dt>
<dd>
<p>Refitted estimate of L corresponding to <code>ibest_refit</code>.</p>
</dd>
</dl>
<h3>See Also</h3>

<p><code>varband</code> <code>varband_path</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(123)
p &lt;- 50
n &lt;- 50
true &lt;- varband_gen(p = p, block = 5)
x &lt;- sample_gen(L = true, n = n)
res_cv &lt;- varband_cv(x = x, w = FALSE, nlam = 40, flmin = 0.03)
</code></pre>


</div>