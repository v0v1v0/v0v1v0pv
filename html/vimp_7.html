<div class="container">

<table style="width: 100%;"><tr>
<td>cv_vim</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Nonparametric Intrinsic Variable Importance Estimates and Inference using Cross-fitting</h2>

<h3>Description</h3>

<p>Compute estimates and confidence intervals using cross-fitting for
nonparametric intrinsic variable importance based on the
population-level contrast between the oracle predictiveness using the
feature(s) of interest versus not.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv_vim(
  Y = NULL,
  X = NULL,
  cross_fitted_f1 = NULL,
  cross_fitted_f2 = NULL,
  f1 = NULL,
  f2 = NULL,
  indx = 1,
  V = ifelse(is.null(cross_fitting_folds), 5, length(unique(cross_fitting_folds))),
  sample_splitting = TRUE,
  final_point_estimate = "split",
  sample_splitting_folds = NULL,
  cross_fitting_folds = NULL,
  stratified = FALSE,
  type = "r_squared",
  run_regression = TRUE,
  SL.library = c("SL.glmnet", "SL.xgboost", "SL.mean"),
  alpha = 0.05,
  delta = 0,
  scale = "identity",
  na.rm = FALSE,
  C = rep(1, length(Y)),
  Z = NULL,
  ipc_scale = "identity",
  ipc_weights = rep(1, length(Y)),
  ipc_est_type = "aipw",
  scale_est = TRUE,
  nuisance_estimators_full = NULL,
  nuisance_estimators_reduced = NULL,
  exposure_name = NULL,
  cross_fitted_se = TRUE,
  bootstrap = FALSE,
  b = 1000,
  boot_interval_type = "perc",
  clustered = FALSE,
  cluster_id = rep(NA, length(Y)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>the outcome.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the covariates. If <code>type = "average_value"</code>, then the exposure
variable should be part of <code>X</code>, with its name provided in <code>exposure_name</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitted_f1</code></td>
<td>
<p>the predicted values on validation data from a
flexible estimation technique regressing Y on X in the training data. Provided as
either (a) a vector, where each element is
the predicted value when that observation is part of the validation fold;
or (b) a list of length V, where each element in the list is a set of predictions on the
corresponding validation data fold.
If sample-splitting is requested, then these must be estimated specially; see Details. However,
the resulting vector should be the same length as <code>Y</code>; if using a list, then the summed
length of each element across the list should be the same length as <code>Y</code> (i.e.,
each observation is included in the predictions).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitted_f2</code></td>
<td>
<p>the predicted values on validation data from a
flexible estimation technique regressing either (a) the fitted values in
<code>cross_fitted_f1</code>, or (b) Y, on X withholding the columns in <code>indx</code>.
Provided as either (a) a vector, where each element is
the predicted value when that observation is part of the validation fold;
or (b) a list of length V, where each element in the list is a set of predictions on the
corresponding validation data fold.
If sample-splitting is requested, then these must be estimated specially; see Details. However,
the resulting vector should be the same length as <code>Y</code>; if using a list, then the summed
length of each element across the list should be the same length as <code>Y</code> (i.e.,
each observation is included in the predictions).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f1</code></td>
<td>
<p>the fitted values from a flexible estimation technique
regressing Y on X. If sample-splitting is requested, then these must be
estimated specially; see Details. If <code>cross_fitted_se = TRUE</code>,
then this argument is not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f2</code></td>
<td>
<p>the fitted values from a flexible estimation technique
regressing either (a) <code>f1</code> or (b) Y on X withholding the columns in
<code>indx</code>. If sample-splitting is requested, then these must be
estimated specially; see Details. If <code>cross_fitted_se = TRUE</code>,
then this argument is not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indx</code></td>
<td>
<p>the indices of the covariate(s) to calculate variable
importance for; defaults to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>the number of folds for cross-fitting, defaults to 5. If
<code>sample_splitting = TRUE</code>, then a special type of <code>V</code>-fold cross-fitting
is done. See Details for a more detailed explanation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_splitting</code></td>
<td>
<p>should we use sample-splitting to estimate the full and
reduced predictiveness? Defaults to <code>TRUE</code>, since inferences made using
<code>sample_splitting = FALSE</code> will be invalid for variables with truly zero
importance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final_point_estimate</code></td>
<td>
<p>if sample splitting is used, should the final point estimates
be based on only the sample-split folds used for inference (<code>"split"</code>, the default),
or should they instead be based on the full dataset (<code>"full"</code>) or the average
across the point estimates from each sample split (<code>"average"</code>)? All three
options result in valid point estimates â€“ sample-splitting is only required for valid inference.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_splitting_folds</code></td>
<td>
<p>the folds used for sample-splitting;
these identify the observations that should be used to evaluate
predictiveness based on the full and reduced sets of covariates, respectively.
Only used if <code>run_regression = FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitting_folds</code></td>
<td>
<p>the folds for cross-fitting. Only used if
<code>run_regression = FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stratified</code></td>
<td>
<p>if run_regression = TRUE, then should the generated
folds be stratified based on the outcome (helps to ensure class balance
across cross-validation folds)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>the type of importance to compute; defaults to
<code>r_squared</code>, but other supported options are <code>auc</code>,
<code>accuracy</code>, <code>deviance</code>, and <code>anova</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>run_regression</code></td>
<td>
<p>if outcome Y and covariates X are passed to
<code>vimp_accuracy</code>, and <code>run_regression</code> is <code>TRUE</code>,
then Super Learner will be used; otherwise, variable importance
will be computed using the inputted fitted values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SL.library</code></td>
<td>
<p>a character vector of learners to pass to
<code>SuperLearner</code>, if <code>f1</code> and <code>f2</code> are Y and X,
respectively. Defaults to <code>SL.glmnet</code>, <code>SL.xgboost</code>,
and <code>SL.mean</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the level to compute the confidence interval at.
Defaults to 0.05, corresponding to a 95% confidence interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>the value of the <code class="reqn">\delta</code>-null (i.e., testing if
importance &lt; <code class="reqn">\delta</code>); defaults to 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>should CIs be computed on original ("identity") or
another scale? (options are "log" and "logit")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>should we remove NAs in the outcome and fitted values
in computation? (defaults to <code>FALSE</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>the indicator of coarsening (1 denotes observed, 0 denotes
unobserved).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>either (i) NULL (the default, in which case the argument
<code>C</code> above must be all ones), or (ii) a character vector
specifying the variable(s) among Y and X that are thought to play a
role in the coarsening mechanism. To specify the outcome, use <code>"Y"</code>; to
specify covariates, use a character number corresponding to the desired
position in X (e.g., <code>"1"</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ipc_scale</code></td>
<td>
<p>what scale should the inverse probability weight correction be applied on (if any)?
Defaults to "identity". (other options are "log" and "logit")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ipc_weights</code></td>
<td>
<p>weights for the computed influence curve (i.e.,
inverse probability weights for coarsened-at-random settings).
Assumed to be already inverted (i.e., ipc_weights = 1 / [estimated
probability weights]).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ipc_est_type</code></td>
<td>
<p>the type of procedure used for coarsened-at-random
settings; options are "ipw" (for inverse probability weighting) or
"aipw" (for augmented inverse probability weighting).
Only used if <code>C</code> is not all equal to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale_est</code></td>
<td>
<p>should the point estimate be scaled to be greater than or equal to 0?
Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nuisance_estimators_full</code></td>
<td>
<p>(only used if <code>type = "average_value"</code>)
a list of nuisance function estimators on the
observed data (may be within a specified fold, for cross-fitted estimates).
Specifically: an estimator of the optimal treatment rule; an estimator of the
propensity score under the estimated optimal treatment rule; and an estimator
of the outcome regression when treatment is assigned according to the estimated optimal rule.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nuisance_estimators_reduced</code></td>
<td>
<p>(only used if <code>type = "average_value"</code>)
a list of nuisance function estimators on the
observed data (may be within a specified fold, for cross-fitted estimates).
Specifically: an estimator of the optimal treatment rule; an estimator of the
propensity score under the estimated optimal treatment rule; and an estimator
of the outcome regression when treatment is assigned according to the estimated optimal rule.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exposure_name</code></td>
<td>
<p>(only used if <code>type = "average_value"</code>) the name of
the exposure of interest; binary, with 1 indicating presence of the exposure and
0 indicating absence of the exposure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitted_se</code></td>
<td>
<p>should we use cross-fitting to estimate the standard
errors (<code>TRUE</code>, the default) or not (<code>FALSE</code>)?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bootstrap</code></td>
<td>
<p>should bootstrap-based standard error estimates be computed?
Defaults to <code>FALSE</code> (and currently may only be used if
<code>sample_splitting = FALSE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>the number of bootstrap replicates (only used if <code>bootstrap = TRUE</code>
and <code>sample_splitting = FALSE</code>); defaults to 1000.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boot_interval_type</code></td>
<td>
<p>the type of bootstrap interval (one of <code>"norm"</code>,
<code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, or <code>"bca"</code>, as in
<code>boot{boot.ci}</code>) if requested. Defaults to <code>"perc"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clustered</code></td>
<td>
<p>should the bootstrap resamples be performed on clusters
rather than individual observations? Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster_id</code></td>
<td>
<p>vector of the same length as <code>Y</code> giving the cluster IDs
used for the clustered bootstrap, if <code>clustered</code> is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments to the estimation tool, see "See also".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>We define the population variable importance measure (VIM) for the
group of features (or single feature) <code class="reqn">s</code> with respect to the
predictiveness measure <code class="reqn">V</code> by
</p>
<p style="text-align: center;"><code class="reqn">\psi_{0,s} := V(f_0, P_0) - V(f_{0,s}, P_0),</code>
</p>
<p> where <code class="reqn">f_0</code> is
the population predictiveness maximizing function, <code class="reqn">f_{0,s}</code> is the
population predictiveness maximizing function that is only allowed to access
the features with index not in <code class="reqn">s</code>, and <code class="reqn">P_0</code> is the true
data-generating distribution.
</p>
<p>Cross-fitted VIM estimates are computed differently if sample-splitting
is requested versus if it is not. We recommend using sample-splitting
in most cases, since only in this case will inferences be valid if
the variable(s) of interest have truly zero population importance.
The purpose of cross-fitting is to estimate <code class="reqn">f_0</code> and <code class="reqn">f_{0,s}</code>
on independent data from estimating <code class="reqn">P_0</code>; this can result in improved
performance, especially when using flexible learning algorithms. The purpose
of sample-splitting is to estimate <code class="reqn">f_0</code> and <code class="reqn">f_{0,s}</code> on independent
data; this allows valid inference under the null hypothesis of zero importance.
</p>
<p>Without sample-splitting, cross-fitted VIM estimates are obtained by first
splitting the data into <code class="reqn">K</code> folds; then using each fold in turn as a
hold-out set, constructing estimators <code class="reqn">f_{n,k}</code> and <code class="reqn">f_{n,k,s}</code> of
<code class="reqn">f_0</code> and <code class="reqn">f_{0,s}</code>, respectively on the training data and estimator
<code class="reqn">P_{n,k}</code> of <code class="reqn">P_0</code> using the test data; and finally, computing
</p>
<p style="text-align: center;"><code class="reqn">\psi_{n,s} := K^{(-1)}\sum_{k=1}^K \{V(f_{n,k},P_{n,k}) - V(f_{n,k,s}, P_{n,k})\}.</code>
</p>

<p>With sample-splitting, cross-fitted VIM estimates are obtained by first
splitting the data into <code class="reqn">2K</code> folds. These folds are further divided
into 2 groups of folds. Then, for each fold <code class="reqn">k</code> in the first group,
estimator <code class="reqn">f_{n,k}</code> of <code class="reqn">f_0</code> is constructed using all data besides
the kth fold in the group (i.e., <code class="reqn">(2K - 1)/(2K)</code> of the data) and
estimator <code class="reqn">P_{n,k}</code> of <code class="reqn">P_0</code> is constructed using the held-out data
(i.e., <code class="reqn">1/2K</code> of the data); then, computing
</p>
<p style="text-align: center;"><code class="reqn">v_{n,k} = V(f_{n,k},P_{n,k}).</code>
</p>

<p>Similarly, for each fold <code class="reqn">k</code> in the second group,
estimator <code class="reqn">f_{n,k,s}</code> of <code class="reqn">f_{0,s}</code> is constructed using all data
besides the kth fold in the group (i.e., <code class="reqn">(2K - 1)/(2K)</code> of the data)
and estimator <code class="reqn">P_{n,k}</code> of <code class="reqn">P_0</code> is constructed using the held-out
data (i.e., <code class="reqn">1/2K</code> of the data); then, computing
</p>
<p style="text-align: center;"><code class="reqn">v_{n,k,s} = V(f_{n,k,s},P_{n,k}).</code>
</p>

<p>Finally,
</p>
<p style="text-align: center;"><code class="reqn">\psi_{n,s} := K^{(-1)}\sum_{k=1}^K \{v_{n,k} - v_{n,k,s}\}.</code>
</p>

<p>See the paper by Williamson, Gilbert, Simon, and Carone for more
details on the mathematics behind the <code>cv_vim</code> function, and the
validity of the confidence intervals.
</p>
<p>In the interest of transparency, we return most of the calculations
within the <code>vim</code> object. This results in a list including:
</p>

<dl>
<dt>s</dt>
<dd>
<p>the column(s) to calculate variable importance for</p>
</dd>
<dt>SL.library</dt>
<dd>
<p>the library of learners passed to <code>SuperLearner</code></p>
</dd>
<dt>full_fit</dt>
<dd>
<p>the fitted values of the chosen method fit to the full data (a list, for train and test data)</p>
</dd>
<dt>red_fit</dt>
<dd>
<p>the fitted values of the chosen method fit to the reduced data (a list, for train and test data)</p>
</dd>
<dt>est</dt>
<dd>
<p>the estimated variable importance</p>
</dd>
<dt>naive</dt>
<dd>
<p>the naive estimator of variable importance</p>
</dd>
<dt>eif</dt>
<dd>
<p>the estimated efficient influence function</p>
</dd>
<dt>eif_full</dt>
<dd>
<p>the estimated efficient influence function for the full regression</p>
</dd>
<dt>eif_reduced</dt>
<dd>
<p>the estimated efficient influence function for the reduced regression</p>
</dd>
<dt>se</dt>
<dd>
<p>the standard error for the estimated variable importance</p>
</dd>
<dt>ci</dt>
<dd>
<p>the <code class="reqn">(1-\alpha) \times 100</code>% confidence interval for the variable importance estimate</p>
</dd>
<dt>test</dt>
<dd>
<p>a decision to either reject (TRUE) or not reject (FALSE) the null hypothesis, based on a conservative test</p>
</dd>
<dt>p_value</dt>
<dd>
<p>a p-value based on the same test as <code>test</code></p>
</dd>
<dt>full_mod</dt>
<dd>
<p>the object returned by the estimation procedure for the full data regression (if applicable)</p>
</dd>
<dt>red_mod</dt>
<dd>
<p>the object returned by the estimation procedure for the reduced data regression (if applicable)</p>
</dd>
<dt>alpha</dt>
<dd>
<p>the level, for confidence interval calculation</p>
</dd>
<dt>sample_splitting_folds</dt>
<dd>
<p>the folds used for hypothesis testing</p>
</dd>
<dt>cross_fitting_folds</dt>
<dd>
<p>the folds used for cross-fitting</p>
</dd>
<dt>y</dt>
<dd>
<p>the outcome</p>
</dd>
<dt>ipc_weights</dt>
<dd>
<p>the weights</p>
</dd>
<dt>cluster_id</dt>
<dd>
<p>the cluster IDs</p>
</dd>
<dt>mat</dt>
<dd>
<p>a tibble with the estimate, SE, CI, hypothesis testing decision, and p-value</p>
</dd>
</dl>
<h3>Value</h3>

<p>An object of class <code>vim</code>. See Details for more information.
</p>


<h3>See Also</h3>

<p><code>SuperLearner</code> for specific usage of the
<code>SuperLearner</code> function and package.
</p>


<h3>Examples</h3>

<pre><code class="language-R">n &lt;- 100
p &lt;- 2
# generate the data
x &lt;- data.frame(replicate(p, stats::runif(n, -5, 5)))

# apply the function to the x's
smooth &lt;- (x[,1]/5)^2*(x[,1]+7)/5 + (x[,2]/3)^2

# generate Y ~ Normal (smooth, 1)
y &lt;- as.matrix(smooth + stats::rnorm(n, 0, 1))

# set up a library for SuperLearner; note simple library for speed
library("SuperLearner")
learners &lt;- c("SL.glm")

# -----------------------------------------
# using Super Learner (with a small number of folds, for illustration only)
# -----------------------------------------
set.seed(4747)
est &lt;- cv_vim(Y = y, X = x, indx = 2, V = 2,
type = "r_squared", run_regression = TRUE,
SL.library = learners, cvControl = list(V = 2), alpha = 0.05)

# ------------------------------------------
# doing things by hand, and plugging them in
# (with a small number of folds, for illustration only)
# ------------------------------------------
# set up the folds
indx &lt;- 2
V &lt;- 2
Y &lt;- matrix(y)
set.seed(4747)
# Note that the CV.SuperLearner should be run with an outer layer
# of 2*V folds (for V-fold cross-fitted importance)
full_cv_fit &lt;- suppressWarnings(SuperLearner::CV.SuperLearner(
Y = Y, X = x, SL.library = learners, cvControl = list(V = 2 * V),
innerCvControl = list(list(V = V))
))
full_cv_preds &lt;- full_cv_fit$SL.predict
# use the same cross-fitting folds for reduced
reduced_cv_fit &lt;- suppressWarnings(SuperLearner::CV.SuperLearner(
    Y = Y, X = x[, -indx, drop = FALSE], SL.library = learners,
    cvControl = SuperLearner::SuperLearner.CV.control(
        V = 2 * V, validRows = full_cv_fit$folds
    ),
    innerCvControl = list(list(V = V))
))
reduced_cv_preds &lt;- reduced_cv_fit$SL.predict
# for hypothesis testing
cross_fitting_folds &lt;- get_cv_sl_folds(full_cv_fit$folds)
set.seed(1234)
sample_splitting_folds &lt;- make_folds(unique(cross_fitting_folds), V = 2)
set.seed(5678)
est &lt;- cv_vim(Y = y, cross_fitted_f1 = full_cv_preds,
cross_fitted_f2 = reduced_cv_preds, indx = 2, delta = 0, V = V, type = "r_squared",
cross_fitting_folds = cross_fitting_folds,
sample_splitting_folds = sample_splitting_folds,
run_regression = FALSE, alpha = 0.05, na.rm = TRUE)

</code></pre>


</div>