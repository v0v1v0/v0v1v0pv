<div class="container">

<table style="width: 100%;"><tr>
<td>vimp_rsquared</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Nonparametric Intrinsic Variable Importance Estimates: R-squared</h2>

<h3>Description</h3>

<p>Compute estimates of and confidence intervals for nonparametric $R^2$-based
intrinsic variable importance. This is a wrapper function for <code>cv_vim</code>,
with <code>type = "r_squared"</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vimp_rsquared(
  Y = NULL,
  X = NULL,
  cross_fitted_f1 = NULL,
  cross_fitted_f2 = NULL,
  f1 = NULL,
  f2 = NULL,
  indx = 1,
  V = 10,
  run_regression = TRUE,
  SL.library = c("SL.glmnet", "SL.xgboost", "SL.mean"),
  alpha = 0.05,
  delta = 0,
  na.rm = FALSE,
  final_point_estimate = "split",
  cross_fitting_folds = NULL,
  sample_splitting_folds = NULL,
  stratified = FALSE,
  C = rep(1, length(Y)),
  Z = NULL,
  ipc_weights = rep(1, length(Y)),
  scale = "logit",
  ipc_est_type = "aipw",
  scale_est = TRUE,
  cross_fitted_se = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>the outcome.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the covariates. If <code>type = "average_value"</code>, then the exposure
variable should be part of <code>X</code>, with its name provided in <code>exposure_name</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitted_f1</code></td>
<td>
<p>the predicted values on validation data from a
flexible estimation technique regressing Y on X in the training data. Provided as
either (a) a vector, where each element is
the predicted value when that observation is part of the validation fold;
or (b) a list of length V, where each element in the list is a set of predictions on the
corresponding validation data fold.
If sample-splitting is requested, then these must be estimated specially; see Details. However,
the resulting vector should be the same length as <code>Y</code>; if using a list, then the summed
length of each element across the list should be the same length as <code>Y</code> (i.e.,
each observation is included in the predictions).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitted_f2</code></td>
<td>
<p>the predicted values on validation data from a
flexible estimation technique regressing either (a) the fitted values in
<code>cross_fitted_f1</code>, or (b) Y, on X withholding the columns in <code>indx</code>.
Provided as either (a) a vector, where each element is
the predicted value when that observation is part of the validation fold;
or (b) a list of length V, where each element in the list is a set of predictions on the
corresponding validation data fold.
If sample-splitting is requested, then these must be estimated specially; see Details. However,
the resulting vector should be the same length as <code>Y</code>; if using a list, then the summed
length of each element across the list should be the same length as <code>Y</code> (i.e.,
each observation is included in the predictions).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f1</code></td>
<td>
<p>the fitted values from a flexible estimation technique
regressing Y on X. If sample-splitting is requested, then these must be
estimated specially; see Details. If <code>cross_fitted_se = TRUE</code>,
then this argument is not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f2</code></td>
<td>
<p>the fitted values from a flexible estimation technique
regressing either (a) <code>f1</code> or (b) Y on X withholding the columns in
<code>indx</code>. If sample-splitting is requested, then these must be
estimated specially; see Details. If <code>cross_fitted_se = TRUE</code>,
then this argument is not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indx</code></td>
<td>
<p>the indices of the covariate(s) to calculate variable
importance for; defaults to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>the number of folds for cross-fitting, defaults to 5. If
<code>sample_splitting = TRUE</code>, then a special type of <code>V</code>-fold cross-fitting
is done. See Details for a more detailed explanation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>run_regression</code></td>
<td>
<p>if outcome Y and covariates X are passed to
<code>vimp_accuracy</code>, and <code>run_regression</code> is <code>TRUE</code>,
then Super Learner will be used; otherwise, variable importance
will be computed using the inputted fitted values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SL.library</code></td>
<td>
<p>a character vector of learners to pass to
<code>SuperLearner</code>, if <code>f1</code> and <code>f2</code> are Y and X,
respectively. Defaults to <code>SL.glmnet</code>, <code>SL.xgboost</code>,
and <code>SL.mean</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the level to compute the confidence interval at.
Defaults to 0.05, corresponding to a 95% confidence interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>the value of the <code class="reqn">\delta</code>-null (i.e., testing if
importance &lt; <code class="reqn">\delta</code>); defaults to 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>should we remove NAs in the outcome and fitted values
in computation? (defaults to <code>FALSE</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final_point_estimate</code></td>
<td>
<p>if sample splitting is used, should the final point estimates
be based on only the sample-split folds used for inference (<code>"split"</code>, the default),
or should they instead be based on the full dataset (<code>"full"</code>) or the average
across the point estimates from each sample split (<code>"average"</code>)? All three
options result in valid point estimates â€“ sample-splitting is only required for valid inference.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitting_folds</code></td>
<td>
<p>the folds for cross-fitting. Only used if
<code>run_regression = FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_splitting_folds</code></td>
<td>
<p>the folds used for sample-splitting;
these identify the observations that should be used to evaluate
predictiveness based on the full and reduced sets of covariates, respectively.
Only used if <code>run_regression = FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stratified</code></td>
<td>
<p>if run_regression = TRUE, then should the generated
folds be stratified based on the outcome (helps to ensure class balance
across cross-validation folds)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>the indicator of coarsening (1 denotes observed, 0 denotes
unobserved).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>either (i) NULL (the default, in which case the argument
<code>C</code> above must be all ones), or (ii) a character vector
specifying the variable(s) among Y and X that are thought to play a
role in the coarsening mechanism. To specify the outcome, use <code>"Y"</code>; to
specify covariates, use a character number corresponding to the desired
position in X (e.g., <code>"1"</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ipc_weights</code></td>
<td>
<p>weights for the computed influence curve (i.e.,
inverse probability weights for coarsened-at-random settings).
Assumed to be already inverted (i.e., ipc_weights = 1 / [estimated
probability weights]).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>should CIs be computed on original ("identity") or
another scale? (options are "log" and "logit")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ipc_est_type</code></td>
<td>
<p>the type of procedure used for coarsened-at-random
settings; options are "ipw" (for inverse probability weighting) or
"aipw" (for augmented inverse probability weighting).
Only used if <code>C</code> is not all equal to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale_est</code></td>
<td>
<p>should the point estimate be scaled to be greater than or equal to 0?
Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_fitted_se</code></td>
<td>
<p>should we use cross-fitting to estimate the standard
errors (<code>TRUE</code>, the default) or not (<code>FALSE</code>)?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments to the estimation tool, see "See also".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>We define the population variable importance measure (VIM) for the
group of features (or single feature) <code class="reqn">s</code> with respect to the
predictiveness measure <code class="reqn">V</code> by
</p>
<p style="text-align: center;"><code class="reqn">\psi_{0,s} := V(f_0, P_0) - V(f_{0,s}, P_0),</code>
</p>
<p> where <code class="reqn">f_0</code> is
the population predictiveness maximizing function, <code class="reqn">f_{0,s}</code> is the
population predictiveness maximizing function that is only allowed to access
the features with index not in <code class="reqn">s</code>, and <code class="reqn">P_0</code> is the true
data-generating distribution.
</p>
<p>Cross-fitted VIM estimates are computed differently if sample-splitting
is requested versus if it is not. We recommend using sample-splitting
in most cases, since only in this case will inferences be valid if
the variable(s) of interest have truly zero population importance.
The purpose of cross-fitting is to estimate <code class="reqn">f_0</code> and <code class="reqn">f_{0,s}</code>
on independent data from estimating <code class="reqn">P_0</code>; this can result in improved
performance, especially when using flexible learning algorithms. The purpose
of sample-splitting is to estimate <code class="reqn">f_0</code> and <code class="reqn">f_{0,s}</code> on independent
data; this allows valid inference under the null hypothesis of zero importance.
</p>
<p>Without sample-splitting, cross-fitted VIM estimates are obtained by first
splitting the data into <code class="reqn">K</code> folds; then using each fold in turn as a
hold-out set, constructing estimators <code class="reqn">f_{n,k}</code> and <code class="reqn">f_{n,k,s}</code> of
<code class="reqn">f_0</code> and <code class="reqn">f_{0,s}</code>, respectively on the training data and estimator
<code class="reqn">P_{n,k}</code> of <code class="reqn">P_0</code> using the test data; and finally, computing
</p>
<p style="text-align: center;"><code class="reqn">\psi_{n,s} := K^{(-1)}\sum_{k=1}^K \{V(f_{n,k},P_{n,k}) - V(f_{n,k,s}, P_{n,k})\}.</code>
</p>

<p>With sample-splitting, cross-fitted VIM estimates are obtained by first
splitting the data into <code class="reqn">2K</code> folds. These folds are further divided
into 2 groups of folds. Then, for each fold <code class="reqn">k</code> in the first group,
estimator <code class="reqn">f_{n,k}</code> of <code class="reqn">f_0</code> is constructed using all data besides
the kth fold in the group (i.e., <code class="reqn">(2K - 1)/(2K)</code> of the data) and
estimator <code class="reqn">P_{n,k}</code> of <code class="reqn">P_0</code> is constructed using the held-out data
(i.e., <code class="reqn">1/2K</code> of the data); then, computing
</p>
<p style="text-align: center;"><code class="reqn">v_{n,k} = V(f_{n,k},P_{n,k}).</code>
</p>

<p>Similarly, for each fold <code class="reqn">k</code> in the second group,
estimator <code class="reqn">f_{n,k,s}</code> of <code class="reqn">f_{0,s}</code> is constructed using all data
besides the kth fold in the group (i.e., <code class="reqn">(2K - 1)/(2K)</code> of the data)
and estimator <code class="reqn">P_{n,k}</code> of <code class="reqn">P_0</code> is constructed using the held-out
data (i.e., <code class="reqn">1/2K</code> of the data); then, computing
</p>
<p style="text-align: center;"><code class="reqn">v_{n,k,s} = V(f_{n,k,s},P_{n,k}).</code>
</p>

<p>Finally,
</p>
<p style="text-align: center;"><code class="reqn">\psi_{n,s} := K^{(-1)}\sum_{k=1}^K \{v_{n,k} - v_{n,k,s}\}.</code>
</p>

<p>See the paper by Williamson, Gilbert, Simon, and Carone for more
details on the mathematics behind the <code>cv_vim</code> function, and the
validity of the confidence intervals.
</p>
<p>In the interest of transparency, we return most of the calculations
within the <code>vim</code> object. This results in a list including:
</p>

<dl>
<dt>s</dt>
<dd>
<p>the column(s) to calculate variable importance for</p>
</dd>
<dt>SL.library</dt>
<dd>
<p>the library of learners passed to <code>SuperLearner</code></p>
</dd>
<dt>full_fit</dt>
<dd>
<p>the fitted values of the chosen method fit to the full data (a list, for train and test data)</p>
</dd>
<dt>red_fit</dt>
<dd>
<p>the fitted values of the chosen method fit to the reduced data (a list, for train and test data)</p>
</dd>
<dt>est</dt>
<dd>
<p>the estimated variable importance</p>
</dd>
<dt>naive</dt>
<dd>
<p>the naive estimator of variable importance</p>
</dd>
<dt>eif</dt>
<dd>
<p>the estimated efficient influence function</p>
</dd>
<dt>eif_full</dt>
<dd>
<p>the estimated efficient influence function for the full regression</p>
</dd>
<dt>eif_reduced</dt>
<dd>
<p>the estimated efficient influence function for the reduced regression</p>
</dd>
<dt>se</dt>
<dd>
<p>the standard error for the estimated variable importance</p>
</dd>
<dt>ci</dt>
<dd>
<p>the <code class="reqn">(1-\alpha) \times 100</code>% confidence interval for the variable importance estimate</p>
</dd>
<dt>test</dt>
<dd>
<p>a decision to either reject (TRUE) or not reject (FALSE) the null hypothesis, based on a conservative test</p>
</dd>
<dt>p_value</dt>
<dd>
<p>a p-value based on the same test as <code>test</code></p>
</dd>
<dt>full_mod</dt>
<dd>
<p>the object returned by the estimation procedure for the full data regression (if applicable)</p>
</dd>
<dt>red_mod</dt>
<dd>
<p>the object returned by the estimation procedure for the reduced data regression (if applicable)</p>
</dd>
<dt>alpha</dt>
<dd>
<p>the level, for confidence interval calculation</p>
</dd>
<dt>sample_splitting_folds</dt>
<dd>
<p>the folds used for hypothesis testing</p>
</dd>
<dt>cross_fitting_folds</dt>
<dd>
<p>the folds used for cross-fitting</p>
</dd>
<dt>y</dt>
<dd>
<p>the outcome</p>
</dd>
<dt>ipc_weights</dt>
<dd>
<p>the weights</p>
</dd>
<dt>cluster_id</dt>
<dd>
<p>the cluster IDs</p>
</dd>
<dt>mat</dt>
<dd>
<p>a tibble with the estimate, SE, CI, hypothesis testing decision, and p-value</p>
</dd>
</dl>
<h3>Value</h3>

<p>An object of classes <code>vim</code> and <code>vim_rsquared</code>.
See Details for more information.
</p>


<h3>See Also</h3>

<p><code>SuperLearner</code> for specific usage of the
<code>SuperLearner</code> function and package.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate the data
# generate X
p &lt;- 2
n &lt;- 100
x &lt;- data.frame(replicate(p, stats::runif(n, -5, 5)))

# apply the function to the x's
smooth &lt;- (x[,1]/5)^2*(x[,1]+7)/5 + (x[,2]/3)^2

# generate Y ~ Normal (smooth, 1)
y &lt;- smooth + stats::rnorm(n, 0, 1)

# set up a library for SuperLearner; note simple library for speed
library("SuperLearner")
learners &lt;- c("SL.glm", "SL.mean")

# estimate (with a small number of folds, for illustration only)
est &lt;- vimp_rsquared(y, x, indx = 2,
           alpha = 0.05, run_regression = TRUE,
           SL.library = learners, V = 2, cvControl = list(V = 2))

</code></pre>


</div>