<div class="container">

<table style="width: 100%;"><tr>
<td>varbvsmix</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit linear regression with mixture-of-normals priors using
variational approximation methods.</h2>

<h3>Description</h3>

<p>Find the "best" fully-factorized approximation to the
posterior distribution of the coefficients, with linear regression
likelihood and mixture-of-normals priors on the coefficients. By
"best", we mean the approximating distribution that locally minimizes
the Kullback-Leibler divergence between the approximating distribution
and the exact posterior. In the original formulation (see
<code>varbvs</code>), each regression coefficient was drawn
identically from a spike-and-slab prior. Here, we instead formulate
the “slab” as a mixture of normals.</p>


<h3>Usage</h3>

<pre><code class="language-R">  varbvsmix(X, Z, y, sa, sigma, w, alpha, mu, update.sigma, update.sa,
            update.w, w.penalty, drop.threshold = 1e-8, tol = 1e-4,
            maxiter = 1e4, update.order = 1:ncol(X), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>n x p input matrix, where n is the number of samples, and p
is the number of variables. X cannot be sparse, and cannot have any
missing values (NA).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>n x m covariate data matrix, where m is the number of
covariates. Do not supply an intercept as a covariate (i.e., a
column of ones), because an intercept is automatically included in
the regression model. For no covariates, set <code>Z = NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector of length n containing values of the continuous
outcome.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sa</code></td>
<td>
<p>Vector specifying the prior variance of the regression
coefficients (scaled by <code>sigma</code>) for each mixture component. If
not specified, a "reasonable" set of prior variances is
automatically selected based on a simple regression analysis in
which all variables (columns of <code>X</code>) are treated as
independent. To override this default, set <code>sa</code> to vector of
variances in which the first mixture component is the "spike", and
therefore should be zero. Alternatively, <code>sa</code> may be an integer
greater than 1, in which case this controls the number of mixture
components, and the variances of the individual mixture components
are automatically selected as described.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Residual variance parameter. If missing, it is
automatically fitted to the data by computing an approximate
maximum-likelihood estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>If missing, it is automatically fitted to the data by
computing an approximate maximum-likelihood estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Initial estimates of the approximate posterior mixture
assignment probabilities. These should be specified as a p x K
matrix, where K is the number of mixture components. Each row must
add up to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Initial estimates of the approximate regression coefficients
conditioned on being drawn from each of the K mixture
components. These estimates should be provided as a p x K matrix,
where K is the number of mixture components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.sigma</code></td>
<td>
<p>If <code>TRUE</code>, sigma is fitted to data using an
approximate EM algorithm, in which case argument <code>sigma</code>, if
provided, is the initial estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.sa</code></td>
<td>
<p>Currently, estimate of mixture component variances is
not implemented, so this must be set to <code>TRUE</code>, otherwise an
error will be generated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.w</code></td>
<td>
<p>If <code>TRUE</code>, mixture weights are fitted using an
approximate EM algorithm, in which case argument <code>w</code>, if
provided, is the initial estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.penalty</code></td>
<td>
<p>Penalty term for the mixture weights. It is useful
for "regularizing" the estimate of <code>w</code> when we do not have a
lot of information. It should be a vector with one positive entry
for each mixture component. Larger values place more weight on the
corresponding mixture components. It is based on the Dirichlet
distribution with parameters <code>w.penalty</code>. The default is a
vector of ones, which reduces to a uniform prior on <code>w</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop.threshold</code></td>
<td>
<p>Posterior probability threshold for dropping
mixture components. Should be a positive number close to zero. If,
at any point during the optimization, all posterior mixture
assignment probabilities for a given mixture component <code>k</code> are
less than <code>drop.threshold</code>, the mixture weight for component
<code>k</code> is automatically set to zero. Set <code>drop.threshold</code> to
zero to disable this behaviour. Setting larger values for
<code>drop.threshold</code> may improve computation speed at a small cost
to numerical accuracy of the final results.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Convergence tolerance for co-ordinate ascent updates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>Maximum number of co-ordinate ascent iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.order</code></td>
<td>
<p>Order of the co-ordinate ascent updates for
fitting the variational approximation. The default is
<code>update.order = 1:p</code>, where <code>p</code> is the number of variables
(the number of columns of <code>X</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>verbose = TRUE</code>, print progress of algorithm
to console.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See <a href="https://www.overleaf.com/8954189vvpqnwpxhvhq">https://www.overleaf.com/8954189vvpqnwpxhvhq</a>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>c("varbvsmix","list")</code>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>Number of data samples used to fit model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu.cov</code></td>
<td>
<p>Posterior mean regression coefficients for covariates,
including intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.sigma</code></td>
<td>
<p>If <code>TRUE</code>, residual variance parameter
<code>sigma</code> was fit to data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.sa</code></td>
<td>
<p>If <code>TRUE</code>, mixture variances were fit to data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.w</code></td>
<td>
<p>If <code>TRUE</code>, mixture weights were fit to data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.penalty</code></td>
<td>
<p>Penalty used for updating mixture weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop.threshold</code></td>
<td>
<p>Posterior probabiltiy threshold used in the
optimization procedure for setting mixture weights to zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Fitted or user-specified residual variance parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sa</code></td>
<td>
<p>User-specified mixture variances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>Fitted or user-specified mixture weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Variational estimates of posterior mixture assignent
probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Variational estimates of posterior mean coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>Variational estimates of posterior variances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lfsr</code></td>
<td>
<p>Local false sign rate (LFSR) for each variable computed
from variational estimates of posterior assignment probabilities and
posterior means and variances. See Stephens (2017) for a definition
of the LFSR.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logZ</code></td>
<td>
<p>Variational lower bound to marginal log-likelihood at each
iteration of the co-ordinate ascent algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>err</code></td>
<td>
<p>Maximum difference in the variational posterior
probabilities at each iteration of the co-ordinate ascent
algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nzw</code></td>
<td>
<p>Number of nonzero mixture components (including the
"spike") at each iteration of the co-ordinate ascent algorithm.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Peter Carbonetto <a href="mailto:peter.carbonetto@gmail.com">peter.carbonetto@gmail.com</a></p>


<h3>References</h3>

<p>M. Stephens (2017). False discovery rates: a new deal.
<em>Biostatistics</em> <b>18</b>, 275–294.
</p>


<h3>See Also</h3>

<p><code>varbvs</code></p>


<h3>Examples</h3>

<pre><code class="language-R">
# Generate the data set.
set.seed(1)
n    &lt;- 200
p    &lt;- 500
X    &lt;- randn(n,p)
sd   &lt;- c(0,0.2,0.5)
w    &lt;- c(0.9,0.05,0.05)
k    &lt;- sample(length(w),p,replace = TRUE,prob = w)
beta &lt;- sd[k] * rnorm(p)
y    &lt;- c(X %*% beta + rnorm(n))

# Fit the model to the data, in which the variances of the mixture
# prior are automatically selected.
fit1 &lt;- varbvsmix(X,NULL,y)

# Fit the model, but use only 3 mixture components in the prior
# instead of the default of 20.
fit2 &lt;- varbvsmix(X,NULL,y,3)

# Use the "ground-truth" prior variances (the ones used to simulate
# the data).
fit3 &lt;- varbvsmix(X,NULL,y,sd^2)

# Compare predicted outcomes against observed outcomes.
y.fit1 &lt;- predict(fit1,X)
print(cor(y,y.fit1))

## Not run: 
library(lattice)
print(xyplot(beta.est ~ beta.true,
             data.frame(beta.true = beta,
                        beta.fitted = rowSums(fit$alpha * fit$mu)),
             pch = 20,col = "royalblue",cex = 1))

## End(Not run)
</code></pre>


</div>