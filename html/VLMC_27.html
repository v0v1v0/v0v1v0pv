<div class="container">

<table style="width: 100%;"><tr>
<td>residuals.vlmc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute Residuals of a Fitted VLMC Object</h2>

<h3>Description</h3>

<p>Compute residuals of a fitted <code>vlmc</code> object.
</p>
<p>This is yet a matter of research and may change in the future.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'vlmc'
residuals(object,
        type = c("classwise",
                 "deviance", "pearson", "working", "response", "partial"),
        y = object$y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>typically the result of <code>vlmc(..)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The type of residuals to compute, defaults to
<code>"classwise"</code> which returns an <code class="reqn">n \times m</code> matrix,
see below.  The other types only make sense when the discrete
values of <code>y</code> are ordered which always includes the binary case
(<code class="reqn">m=2</code>).
<br>
The <code>"deviance"</code> residuals <code class="reqn">r</code> are defined similarly as for logistic
regression, see below.
<br>
"pearson", "working" and "response" are currently
identical and give the difference of the underlying integer code (of
the discrete data).

<b>Note</b> that <code>"partial"</code> residuals are not yet defined!
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>discrete time series with respect to which the residuals are
to be computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>possibly further arguments (none at the moment).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>If <code>type = "classwise"</code> (the default), a numeric matrix of dimension
<code class="reqn">n \times m</code> of values <code class="reqn">I_{i,j} - p_{i,j}</code> where the indicator <code class="reqn">I_{i,j}</code> is 1 iff
<code>y[i] == a[j]</code> and <code>a</code> is the alphabet (or levels) of
<code>y</code>, and <code class="reqn">p_{i,j}</code> are the elements of the estimated (1-step
ahead) predicted probabilities, <code>p &lt;- predict(object)</code>.
Hence, for each <code class="reqn">i</code>, the only positive residual stands for the
observed class.
</p>
<p>For all other <code>type</code>s, the result is
a numeric vector of the length of the original time-series (with first
element <code>NA</code>).<br>
For <code>type = "deviance"</code>,
<code class="reqn">r_i = \pm\sqrt{-2\log(P_i)}</code>
where <code class="reqn">P_i</code> is the predicted probability for the i-th
observation which is the same as <code class="reqn">p_{i,y_i}</code> above (now
assuming <code class="reqn">y_i \in \{1,2,\dots,m</code>).
The sum of the squared deviance residuals <em>is</em> the deviance of
the fitted model.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code>vlmc</code>,<code>deviance.vlmc</code>, and
<code>RCplot</code> for a novel residual plot.</p>


<h3>Examples</h3>

<pre><code class="language-R">example(vlmc)
rp &lt;- residuals(vlmc.pres)
stopifnot(all(abs(apply(rp[-1,],1,sum)) &lt; 1e-15))
matplot(seq(presidents), rp, ylab = "residuals", type="l")
## ``Tukey-Anscombe'' (the following is first stab at plot method):
matplot(fitted(vlmc.pres), rp, ylab = "residuals", xaxt = "n",
        type="b", pch=vlmc.pres$alpha)
axis(1, at = 0:(vlmc.pres$alpha.len-1),
     labels = strsplit(vlmc.pres$alpha,"")[[1]])


summary(rd &lt;- residuals(vlmc.pres, type = "dev"))
rd[1:7]
## sum of squared dev.residuals === deviance :
all.equal(sum(rd[-1] ^ 2),
          deviance(vlmc.pres))

</code></pre>


</div>