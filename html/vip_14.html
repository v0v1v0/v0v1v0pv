<div class="container">

<table style="width: 100%;"><tr>
<td>vi_firm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Variance-based variable importance</h2>

<h3>Description</h3>

<p>Compute variance-based variable importance (VI) scores using a simple
<em>feature importance ranking measure</em> (FIRM) approach; for details, see
<a href="https://arxiv.org/abs/1805.04755">Greenwell et al. (2018)</a> and
<a href="https://arxiv.org/abs/1904.03959">Scholbeck et al. (2019)</a>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vi_firm(object, ...)

## Default S3 method:
vi_firm(
  object,
  feature_names = NULL,
  train = NULL,
  var_fun = NULL,
  var_continuous = stats::sd,
  var_categorical = function(x) diff(range(x))/4,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A fitted model object (e.g., a
randomForest object).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to be passed on to the <code>pdp::partial()</code>
function (e.g., <code>ice = TRUE</code>, <code>prob = TRUE</code>, or a prediction wrapper via the
<code>pred.fun</code> argument); see <code>?pdp::partial</code> for details on these and other
useful arguments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>feature_names</code></td>
<td>
<p>Character string giving the names of the predictor
variables (i.e., features) of interest. If <code>NULL</code> (the default) then the
internal <code>get_feature_names()</code> function will be called to try and extract
them automatically. It is good practice to always specify this argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>
<p>A matrix-like R object (e.g., a data frame or matrix)
containing the training data. If <code>NULL</code> (the default) then the
internal <code>get_training_data()</code> function will be called to try and extract it
automatically. It is good practice to always specify this argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_fun</code></td>
<td>
<p>Deprecated; use <code>var_continuous</code> and <code>var_categorical</code>
instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_continuous</code></td>
<td>
<p>Function used to quantify the variability of effects
for continuous features. Defaults to using the sample standard deviation
(i.e., <code>stats::sd()</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_categorical</code></td>
<td>
<p>Function used to quantify the variability of effects
for categorical features. Defaults to using the range divided by four; that
is, <code>function(x) diff(range(x)) / 4</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This approach is based on quantifying the relative "flatness" of the
effect of each feature and assumes the user has some familiarity with the
<code>pdp::partial()</code> function. The  Feature effects can be assessed
using <em>partial dependence</em> (PD) plots (Friedman, 2001) or
<em>individual conditional expectation</em> (ICE) plots (Goldstein et al., 2014).
These methods are model-agnostic and can be applied to any supervised
learning algorithm. By default, relative "flatness" is defined by computing
the standard deviation of the y-axis values for each feature effect plot for
numeric features; for categorical features, the default is to use range
divided by 4. This can be changed via the <code>var_continuous</code> and
<code>var_categorical</code> arguments. See
<a href="https://arxiv.org/abs/1805.04755">Greenwell et al. (2018)</a> for details and
additional examples.
</p>


<h3>Value</h3>

<p>A tidy data frame (i.e., a tibble object) with two
columns:
</p>

<ul>
<li> <p><code>Variable</code> - the corresponding feature name;
</p>
</li>
<li> <p><code>Importance</code> - the associated importance, computed as described in
<a href="https://arxiv.org/abs/1805.04755">Greenwell et al. (2018)</a>.
</p>
</li>
</ul>
<h3>Note</h3>

<p>This approach can provide misleading results in the presence of
interaction effects (akin to interpreting main effect coefficients in a
linear with higher level interaction effects).
</p>


<h3>References</h3>

<p>J. H. Friedman. Greedy function approximation: A gradient boosting machine.
<em>Annals of Statistics</em>, <strong>29</strong>: 1189-1232, 2001.
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J., and Pitkin, E., Peeking Inside the
Black Box: Visualizing Statistical Learning With Plots of Individual
Conditional Expectation. (2014) <em>Journal of Computational and Graphical
Statistics</em>, <strong>24</strong>(1): 44-65, 2015.
</p>
<p>Greenwell, B. M., Boehmke, B. C., and McCarthy, A. J. A Simple
and Effective Model-Based Variable Importance Measure. arXiv preprint
arXiv:1805.04755 (2018).
</p>
<p>Scholbeck, C. A. Scholbeck, and Molnar, C.,  and Heumann C., and Bischl, B.,
and Casalicchio, G. Sampling, Intervention, Prediction, Aggregation: A
Generalized Framework for Model-Agnostic Interpretations. arXiv preprint
arXiv:1904.03959 (2019).
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
#
# A projection pursuit regression example
#

# Load the sample data
data(mtcars)

# Fit a projection pursuit regression model
mtcars.ppr &lt;- ppr(mpg ~ ., data = mtcars, nterms = 1)

# Compute variable importance scores using the FIRM method; note that the pdp
# package knows how to work with a "ppr" object, so there's no need to pass
# the training data or a prediction wrapper, but it's good practice.
vi_firm(mtcars.ppr, train = mtcars)

# For unsopported models, need to define a prediction wrapper; this approach
# will work for ANY model (supported or unsupported, so better to just always
# define it pass it)
pfun &lt;- function(object, newdata) {
  # To use partial dependence, this function needs to return the AVERAGE
  # prediction (for ICE, simply omit the averaging step)
  mean(predict(object, newdata = newdata))
}

# Equivalent to the previous results (but would work if this type of model
# was not explicitly supported)
vi_firm(mtcars.ppr, pred.fun = pfun, train = mtcars)

# Equivalent VI scores, but the output is sorted by default
vi(mtcars.ppr, method = "firm")

# Use MAD to estimate variability of the partial dependence values
vi_firm(mtcars.ppr, var_continuous = stats::mad)

# Plot VI scores
vip(mtcars.ppr, method = "firm", train = mtcars, pred.fun = pfun)

## End(Not run)
</code></pre>


</div>