<div class="container">

<table style="width: 100%;"><tr>
<td>testAudioData</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>voiceR test Audio Data</h2>

<h3>Description</h3>

<p>A test audio features data.frame, obtained by using autoExtract() on
the extended version of testAudioList, found
&lt;a href="https://osf.io/zt5h2/?view_only=348d1d172435449391e8d64547716477"&gt;here&lt;/a&gt;.
</p>


<h3>Format</h3>

<p>'testAudioData'
A data.frame containing 90 observations and 11 variables, which is the result of
applying the autoExtract() function to the extended version of the data found
on testAudioList. This data.frame contains several voice features for 90 audio
files, which correspond to 15 English-speaking participants.
Participants first completed a Baseline Voice Task in which they were
instructed to read two predefined phrases ((1) Bar: "I go to the bar",
(2) Beer: "I drink a beer") aloud in their normal (neutral) voice.
Participants were then instructed to read the predefined phrases in either
a happy or a sad voice. The experimenter requested
each emotion one at a time and in a random sequence to counter-order effects.
Participants were then asked to describe their experience of mimicking the
stated phrases for each of the specified emotional states.
Thus the data contains 6 observations per participant: two observations for
the neutral state, two for the happy simulated state, and two for the sad
simulated state.
Below we also provide information about the columns this data.frame contains:
</p>

<dl>
<dt>ID</dt>
<dd>
<p>Participant identifier</p>
</dd>
<dt>Condition</dt>
<dd>
<p>refers to the intention or emotional aspect that
the speaker is conveying: Happy, or Sad. This component makes
reference to the main point that we want to compare in our data; in the
voiceR package the main comparison component is called Condition, because
it usually refers to experimental conditions.</p>
</dd>
<dt>Dimensions</dt>
<dd>
<p>Phrase participants read: (1) Bar: "I go to the bar";
(2): Beer: "I drink a beer"</p>
</dd>
<dt>duration</dt>
<dd>
<p>Total duration in seconds.</p>
</dd>
<dt>voice_breaks_percent</dt>
<dd>
<p>Proportion of unvoiced frames.</p>
</dd>
<dt>RMS_env</dt>
<dd>
<p>Root mean square of the amplitude envelope.</p>
</dd>
<dt>mean_loudness</dt>
<dd>
<p>Average subjective loudness in sone.</p>
</dd>
<dt>mean_F0</dt>
<dd>
<p>Average fundamental frequency in Hertz.</p>
</dd>
<dt>sd_F0</dt>
<dd>
<p>Standard deviation of the fundamental frequency in Hertz.</p>
</dd>
<dt>mean_entropy</dt>
<dd>
<p>Average Wiener entropy. A value of 0 indicates a pure tone, while a value of 1 indicates white noise.</p>
</dd>
<dt>mean_HNR</dt>
<dd>
<p>Average Harmonics-to-Noise Ratio.</p>
</dd>
</dl>
<h3>Examples</h3>

<pre><code class="language-R">data(testAudioData)
</code></pre>


</div>