<div class="container">

<table style="width: 100%;"><tr>
<td>varCompTest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Variance component testing</h2>

<h3>Description</h3>

<p>Perform a likelihood ratio test to test whether a subset of the variances of the random effects
are equal to zero. The test is defined by two hypotheses, H0 and H1, and the model under H0 is
assumed to be nested within the model under H1. These functions can be used on objects of class
<code>lme</code>-, <code>nlme</code>-, <code>mer</code>-, <code>lmerMod</code>, <code>glmerMod</code>, <code>nlmerMord</code> or <code>SaemixObject</code>.
</p>
<p>It is possible to tests if any subset of the variances are equal to zero. However, the function does not
currently support nested random effects, and assumes that the random effects are Gaussian.
</p>


<h3>Usage</h3>

<pre><code class="language-R">varCompTest(
  m1,
  m0,
  control = list(M = 5000, parallel = T, nb_cores = 1, B = 1000),
  pval.comp = "bounds",
  fim = "extract",
  output = TRUE
)

## S3 method for class 'lme'
varCompTest(
  m1,
  m0,
  control = list(M = 5000, parallel = FALSE, nb_cores = 1, B = 1000),
  pval.comp = "bounds",
  fim = "extract",
  output = TRUE
)

## S3 method for class 'merMod'
varCompTest(
  m1,
  m0,
  control = list(M = 5000, parallel = FALSE, nb_cores = 1, B = 1000),
  pval.comp = "bounds",
  fim = "extract",
  output = TRUE
)

## S3 method for class 'SaemixObject'
varCompTest(
  m1,
  m0,
  control = list(M = 5000, parallel = FALSE, nb_cores = 1, B = 1000),
  pval.comp = "bounds",
  fim = "extract",
  output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>m1</code></td>
<td>
<p>a fit of the model under H1, obtained from <code>nlme</code>, <code>lme4</code>
or <code>saemix</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m0</code></td>
<td>
<p>a fit of the model under H0, obtained from the same package as <code>m0</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>(optional) a list of control options for the computation of the chi-bar-weights (see Details section)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval.comp</code></td>
<td>
<p>(optional) the method to be used to compute the p-value, one of: <code>"bounds"</code> (the default),
<code>"approx"</code> or <code>"both"</code> (see Details section)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fim</code></td>
<td>
<p>(optional) the method to compute the Fisher Information Matrix. Options are: <code>fim="extract"</code> to extract the
FIM computed by the package which was used to fit the models, <code>fim="compute"</code> to evaluate the FIM using parametric
bootstrap, and <code>fim=I</code> with <code>I</code> a positive semidefinite matrix, for a FIM provided by the user.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>
<p>a boolean specifying if any output should be printed in the console (default to TRUE)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The asymptotic distribution of the likelihood ratio test is a chi-bar-square, with weights that need to be
approximated by Monte Carlo methods, apart from some specific cases where they are available explicitly. 
Therefore, the p-value of the test is not exact but approximated. This computation can be time-consuming, so
the default behaviour of the function is to provide bounds on the exact p-value, which can be enough in practice
to decide whether to reject or not the null hypothesis. This is triggered by the option <code>pval.comp="bounds"</code>.
To compute an approximation of the exact p-value, one should use the option <code>pval.comp="approx"</code> or <code>pval.comp="both"</code>.
</p>
<p>When <code>pval.comp="approx"</code> or <code>pval.comp="both"</code>, the weights of the chi-bar-square distribution are computed using Monte Carlo,
which might involve a larger computing time.
</p>
<p>The <code>control</code> argument controls the options for chi-bar-square weights computation. It is a list with the
following elements: <code>M</code> the size of the Monte Carlo simulation, i.e. the number of samples generated, <code>parallel</code> a
boolean to specify if parallel computing should be used, and <code>nbcores</code> the number of cores to be used in case of 
parallel computing. Default is <code>M=5000</code>, <code>parallel=FALSE</code> and <code>nb_cores=1</code>.
If <code>parallel=TRUE</code> but the value of <code>nb_cores</code> is not given, then it is set to the number of detected
cores minus 1
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>

<ul>
<li> <p><code>statistic</code> the likelihood ratio test statistics
</p>
</li>
<li> <p><code>null.value</code> 
</p>
</li>
<li> <p><code>alternative</code> 
</p>
</li>
<li> <p><code>parameters</code> the parameters of the limiting chi-bar-square distribution: the degrees of freedom and
the weights of the chi-bar-square components and the Fisher Information Matrix
</p>
</li>
<li> <p><code>method</code> a character string indicating the name of the test
</p>
</li>
<li> <p><code>pvalue</code> a named vector containing the different p-values computed by the function: using the 
(estimated) weights, using the random sample from the chi-bar-square distribution, and the two bounds on
the p-value.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Charlotte Baey &lt;<a href="mailto:charlotte.baey@univ-lille.fr">charlotte.baey@univ-lille.fr</a>&gt;
</p>


<h3>References</h3>

<p>Baey C, Courn√®de P-H, Kuhn E, 2019. Asymptotic distribution of likelihood ratio test
statistics for variance components in nonlinear mixed effects models. <em>Computational
Statistics and Data Analysis</em> 135:107-122.
</p>
<p>Silvapulle  MJ, Sen PK, 2011. Constrained statistical inference: order, inequality and shape constraints.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># load lme4 package and example dataset
library(lme4)
data(Orthodont, package = "nlme")

# fit the two models under H1 and H0
m1 &lt;- lmer(distance ~ 1 + Sex + age + age*Sex + 
(0 + age | Subject), data = Orthodont, REML = FALSE)
m0 &lt;- lm(distance ~ 1 + Sex + age + age*Sex, data = Orthodont)

# compare them (order is important: m1 comes first)
varCompTest(m1,m0,pval.comp="bounds")

# using nlme
library(nlme)
m1 &lt;- lme(distance ~ 1 + Sex + age + age*Sex, 
random = pdSymm(Subject ~ 1 + age), data = Orthodont, method = "ML")
m0 &lt;- lme(distance ~ 1 + Sex, random = ~ 1 | Subject, data = Orthodont, method = "ML")

varCompTest(m1,m0)

</code></pre>


</div>